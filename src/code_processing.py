#code_processing.py
import openai
import os
from dotenv import load_dotenv
from tqdm import tqdm
import time

load_dotenv()  # load environment variables from .env file

# get OpenAI API key from environment variables
OPEN_API_KEY = os.getenv("OPEN_API_KEY")

# set OpenAI API key
openai.api_key = OPEN_API_KEY

# set retry configuration
MAX_RETRIES = 3
RETRY_DELAY = 5  # in seconds

# code_processing.py
def split_code_into_chunks(code, max_tokens=1000):
    """
    Splits code into chunks of specified size.

    Args:
        code (str): The code to split.
        max_tokens (int): The maximum number of tokens in each chunk.

    Returns:
        A list of code chunks.
    """
    tokens = code.split()
    chunks = []

    for i in range(0, len(tokens), max_tokens):
        chunk = " ".join(tokens[i:i + max_tokens])
        chunks.append(chunk)

    return chunks

def process_file_with_openai(filepath, gpt_version):
    """
    Processes a file using OpenAI's GPT model.

    Args:
        filepath (str): The path of the file to process.
        gpt_version (str): The version of the GPT model to use.

    Returns:
        A list of comments generated by the GPT model.
    """
    with open(filepath, 'r') as f:
        code = f.read()

    chunks = split_code_into_chunks(code)
    comments = []

    for chunk in chunks:
        comment = process_chunk_with_openai(chunk, gpt_version)
        comments.append(comment)

    # Append comments to the code file
    with open(filepath, "a") as f:
        for comment in comments:
            f.write("\n" + comment + "\n")

    # Write comments to a new README file
    readme_path = filepath + '.README.md'
    with open(readme_path, 'w') as f:
        for comment in comments:
            f.write(comment + "\n")

    return readme_path, comments

def process_chunk_with_openai(chunk, gpt_version):
    """
    Processes a code chunk using OpenAI's GPT model.

    Args:
        chunk (str): The code chunk to process.
        gpt_version (str): The version of the GPT model to use.

    Returns:
        A comment generated by the GPT model.
    """
    retries = 0
    while retries < MAX_RETRIES:
        try:
            response = openai.ChatCompletion.create(
                model=f"gpt-{gpt_version}",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant that analyzes and comments code. List any issues you find and suggest improvements and fixes. You can also suggest new features."},
                    {"role": "user", "content": f"Analyze this code:\n{chunk}"}
                ],
                max_tokens=1000  # Adjust this as needed
            )
            comment = response['choices'][0]['message']['content'].strip()
            return comment
        except openai.error.RateLimitError:
            print("Rate limit exceeded. Retrying after delay...")
            time.sleep(RETRY_DELAY)
            retries += 1

    return "Unable to process chunk at the moment. Please try again later."